"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || (function () {
    var ownKeys = function(o) {
        ownKeys = Object.getOwnPropertyNames || function (o) {
            var ar = [];
            for (var k in o) if (Object.prototype.hasOwnProperty.call(o, k)) ar[ar.length] = k;
            return ar;
        };
        return ownKeys(o);
    };
    return function (mod) {
        if (mod && mod.__esModule) return mod;
        var result = {};
        if (mod != null) for (var k = ownKeys(mod), i = 0; i < k.length; i++) if (k[i] !== "default") __createBinding(result, mod, k[i]);
        __setModuleDefault(result, mod);
        return result;
    };
})();
Object.defineProperty(exports, "__esModule", { value: true });
exports.ChatInvoker = void 0;
const vscode = __importStar(require("vscode"));
const config_1 = require("./config");
class ChatInvoker {
    constructor(logger) {
        this.logger = logger;
        this.preferredModel = config_1.Config.get().model.preferred;
        // åˆå§‹åŒ–æ™‚æª¢æŸ¥æ¨¡åž‹å¯ç”¨æ€§
        this.initializeModels();
        // ç›£è½é…ç½®è®Šæ›´
        config_1.Config.onDidChange(() => {
            this.preferredModel = config_1.Config.get().model.preferred;
        });
    }
    /**
     * åˆå§‹åŒ–ä¸¦æª¢æŸ¥å¯ç”¨æ¨¡åž‹
     */
    async initializeModels() {
        try {
            this.logger.info('ðŸ” Checking available chat models...');
            const models = await vscode.lm.selectChatModels();
            if (models.length === 0) {
                this.logger.error('âŒ No chat models available. Enable VS Code Chat API and install a provider. Tip: set "agent-alike-po-bot.model.preferred" to an available id/name/family.');
                return;
            }
            const list = models.map(m => ({ id: m.id, vendor: m.vendor, family: m.family, version: m.version, name: m.name }));
            this.logger.info('âœ… Available chat models:', { count: models.length, models: list, preferred: this.preferredModel });
            // å˜—è©¦é å…ˆè§£æžä¸¦æ‰“å°å°‡ä½¿ç”¨ä¹‹æ¨¡åž‹
            try {
                const selected = await this.selectModelStrict();
                this.logger.info(`ðŸ¤– Using model: ${selected.name}`, { id: selected.id, vendor: selected.vendor, family: selected.family, version: selected.version });
            }
            catch (e) {
                this.logger.error('âŒ Model selection failed', {
                    error: e instanceof Error ? e.message : String(e),
                    hint: 'Check "agent-alike-po-bot.model.preferred" or install/enable a chat model provider.'
                });
            }
            // æª¢æŸ¥é¦–é¸æ¨¡åž‹æ˜¯å¦å¯ç”¨
            if (this.preferredModel) {
                const preferredAvailable = models.some(m => m.id === this.preferredModel || m.name === this.preferredModel || m.family === this.preferredModel);
                if (!preferredAvailable) {
                    this.logger.warn(`âš ï¸ Preferred model '${this.preferredModel}' not available`);
                }
            }
        }
        catch (error) {
            this.logger.error('âŒ Failed to check available models', {
                error: error instanceof Error ? error.message : String(error)
            });
        }
    }
    /**
     * èª¿ç”¨ VS Code å…§å»ºèŠå¤©æ¨¡åž‹
     */
    async invokeChatModel(prompt, options) {
        const startTime = Date.now();
        // æª¢æ¸¬ Host ç’°å¢ƒ
        const hostName = vscode.env.appName;
        const hostVersion = vscode.version;
        this.logger.info('LLM invocation started', {
            hostName,
            hostVersion,
            promptLength: prompt.length,
            preferredModel: this.preferredModel,
            maxTokens: options?.maxTokens,
            temperature: options?.temperature,
            timestamp: new Date().toISOString()
        });
        try {
            this.logger.debug('Invoking VS Code chat model', {
                promptLength: prompt.length,
                preferredModel: this.preferredModel,
                options
            });
            // ä½¿ç”¨ VS Code Chat API
            const response = await this.callVSCodeChatAPI(prompt, options);
            const latencyMs = Date.now() - startTime;
            this.logger.info('LLM invocation completed', {
                latencyMs,
                responseLength: response.text.length,
                promptTokens: response.usage.promptTokens,
                completionTokens: response.usage.completionTokens,
                totalTokens: response.usage.promptTokens + response.usage.completionTokens,
                model: response.modelId || response.modelName,
                provider: response.provider || 'vscode.lm',
                hostName,
                success: true
            });
            // ç°¡æ½”æ‘˜è¦ï¼ˆä¾¿æ–¼äººå·¥æŽƒæï¼‰
            this.logger.info('LLM summary', {
                model: response.modelId || response.modelName,
                provider: response.provider || 'vscode.lm',
                latency_ms: latencyMs,
                tokens: `${response.usage.promptTokens}+${response.usage.completionTokens}=${response.usage.promptTokens + response.usage.completionTokens}`,
                chars_in: prompt.length,
                chars_out: response.text.length
            });
            return response;
        }
        catch (error) {
            const latencyMs = Date.now() - startTime;
            this.logger.error('Chat model invocation failed', {
                latencyMs,
                error: error instanceof Error ? error.message : String(error)
            });
            // åˆ†é¡žéŒ¯èª¤
            const processingError = this.classifyModelError(error);
            throw processingError;
        }
    }
    /**
     * èª¿ç”¨ VS Code Chat APIï¼ˆå¯¦éš›å¯¦ä½œï¼‰
     */
    async callVSCodeChatAPI(prompt, options) {
        const startTime = Date.now();
        try {
            // é¸æ“‡å¯¦éš›å¯ç”¨çš„ VS Code Chat æ¨¡åž‹ï¼ˆä¸åšä»»ä½•æ¨¡æ“¬ï¼‰
            const model = await this.selectModelStrict();
            this.logger.debug(`Using model (raw): ${model.name}`, {
                vendor: model.vendor,
                family: model.family,
                version: model.version,
                id: model.id
            });
            // æ­£è¦åŒ–å¾Œçš„æ¨¡åž‹è­˜åˆ¥ï¼ˆä¾›å¾ŒçºŒä¸€è‡´ä½¿ç”¨ï¼‰
            const normalized = this.normalizeModelMeta(model);
            this.logger.info('Normalized model meta', {
                provider: normalized.provider,
                modelId: normalized.modelId,
                rawName: model.name,
                rawId: model.id,
                family: model.family,
                version: model.version
            });
            // å»ºæ§‹èŠå¤©è«‹æ±‚
            const messages = [
                vscode.LanguageModelChatMessage.User(prompt)
            ];
            // è¨­å®šè«‹æ±‚é¸é …
            const requestOptions = {
                justification: 'Generate response for customer support ticket'
            };
            // ç™¼é€è«‹æ±‚
            const chatResponse = await model.sendRequest(messages, requestOptions);
            // æ”¶é›†å›žæ‡‰
            let responseText = '';
            for await (const fragment of chatResponse.text) {
                responseText += fragment;
            }
            const latencyMs = Date.now() - startTime;
            // ä¼°ç®— token ä½¿ç”¨é‡ï¼ˆVS Code API å¯èƒ½ä¸æä¾›ç²¾ç¢ºæ•¸æ“šï¼‰
            const estimatedPromptTokens = this.estimateTokens(prompt);
            const estimatedCompletionTokens = this.estimateTokens(responseText);
            // é‡ç”¨å…ˆå‰çš„ normalized è®Šæ•¸
            return {
                text: responseText.trim(),
                usage: {
                    promptTokens: estimatedPromptTokens,
                    completionTokens: estimatedCompletionTokens
                },
                latencyMs,
                modelName: model.name,
                provider: normalized.provider,
                modelId: normalized.modelId
            };
        }
        catch (error) {
            this.logger.error('VS Code Chat API invocation failed (strict mode, no fallback)', {
                error: error instanceof Error ? error.message : String(error)
            });
            throw error;
        }
    }
    // ç§»é™¤æ‰€æœ‰æ¨¡æ“¬é‚è¼¯ï¼šä¸æä¾› fallbackï¼Œç¢ºä¿åªç”¨çœŸæ¨¡åž‹
    /**
     * ä¼°ç®— token æ•¸é‡
     */
    estimateTokens(text) {
        // ç°¡åŒ–çš„ token ä¼°ç®—
        const chineseChars = (text.match(/[\u4e00-\u9fff]/g) || []).length;
        const englishWords = (text.match(/[a-zA-Z]+/g) || []).length;
        const otherChars = text.length - chineseChars - englishWords;
        return Math.ceil(chineseChars * 1.5 + englishWords * 1.3 + otherChars * 0.5);
    }
    /**
     * æ­£è¦åŒ–æ¨¡åž‹ä¸­ç¹¼è³‡æ–™ï¼ŒæŠ½å– provider èˆ‡å¯è¾¨è­˜çš„ modelId
     */
    normalizeModelMeta(model) {
        const provider = 'vscode.lm';
        const candidates = [];
        ['id', 'modelId', 'family', 'name'].forEach(k => { if (model && model[k])
            candidates.push(String(model[k])); });
        // åµæ¸¬ gpt-4o / gpt4o å®¶æ—ï¼›å¦å‰‡ç”¨ç¬¬ä¸€å€‹
        const preferred = candidates.find(c => /gpt[-_]?4o/i.test(c)) || candidates[0] || 'unknown-model';
        return { provider, modelId: preferred, display: preferred };
    }
    /**
     * åˆ†é¡žæ¨¡åž‹éŒ¯èª¤
     */
    classifyModelError(error) {
        if (error instanceof Error) {
            const message = error.message.toLowerCase();
            if (message.includes('timeout') || message.includes('timed out')) {
                return { type: 'timeout', message: 'Model request timeout', retryable: true };
            }
            if (message.includes('rate limit') || message.includes('too many requests')) {
                return { type: 'rate_limit', message: 'Model rate limit exceeded', retryable: true };
            }
            if (message.includes('not available') || message.includes('unauthorized')) {
                return { type: 'validation', message: 'Chat model not available or unauthorized', retryable: false };
            }
            return { type: 'model', message: error.message, retryable: true };
        }
        return { type: 'unknown', message: 'Unknown model error', retryable: true };
    }
    // ï¼ˆå·²ç°¡åŒ–ï¼‰checkModelAvailability å·²ç§»é™¤ï¼Œå¦‚éœ€å†åŠ å¯æŽ¡ç”¨æ›´å°åž‹ä»‹é¢
    /**
     * åš´æ ¼é¸æ“‡å¯ç”¨æ¨¡åž‹ï¼š
     * 1) å˜—è©¦ä»¥ preferred æ¯”å° family/name/id
     * 2) æ‰¾ä¸åˆ°å‰‡å›žé€€åˆ°ç¬¬ä¸€å€‹å¯ç”¨æ¨¡åž‹ï¼ˆä»æ˜¯çœŸå¯¦æ¨¡åž‹ï¼‰
     */
    async selectModelStrict() {
        const preferred = this.preferredModel?.trim();
        if (preferred) {
            try {
                const byFamily = await vscode.lm.selectChatModels({ family: preferred });
                if (byFamily.length > 0)
                    return byFamily[0];
            }
            catch { }
            try {
                const all = await vscode.lm.selectChatModels();
                const matched = all.find(m => m.id === preferred || m.name === preferred || m.family === preferred);
                if (matched)
                    return matched;
            }
            catch { }
        }
        const all = await vscode.lm.selectChatModels();
        if (all.length === 0) {
            throw new Error('No VS Code chat models available. Ensure VS Code Chat API is enabled and models are installed.');
        }
        return all[0];
    }
}
exports.ChatInvoker = ChatInvoker;
//# sourceMappingURL=chatInvoker.js.map